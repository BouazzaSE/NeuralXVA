{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from learning.cva_estimator_portfolio_int import CVAEstimatorPortfolioInt\n",
    "from learning.cva_estimator_portfolio_def import CVAEstimatorPortfolioDef\n",
    "from simulation.diffusion_engine import DiffusionEngine\n",
    "import time\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = '100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7a6a7f34d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False # don't allow cudnn to tune for every input size\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `num_coarse_steps`: # of coarse time-steps, *ie* steps at which we price and learn;\n",
    "* `dT`: size of a coarse time-step (uniform time-stepping), should be equal to the simulation horizon in years divided by `num_coarse_steps`;\n",
    "* `num_fine_per_coarse`: # of fine time-steps per coarse time-step, those are steps through which the numerical diffusions are stepping;\n",
    "* `dt`: should be equal to `dT/num_fine_per_coarse`;\n",
    "* `num_paths`: # of diffusion paths ($M$ in the article);\n",
    "* `num_inner_paths`: # of inner-paths for the Nested Monte Carlo benchmark, set to `1` if no NMC benchmark is needed;\n",
    "* `num_defs_per_path`: # of default simulations given each diffusion path ($N$ in the article);\n",
    "* `num_rates`: # of economies, each represented by a 1-factor short-rate;\n",
    "* `num_spreads`: # of counterparties + 1, with one stochastic spread for each counterparty and one for the bank itself;\n",
    "* `R`: correlation matrix, should be `2*num_rates-1+num_spreads` by `2*num_rates-1+num_spreads`;\n",
    "\n",
    "As for the order in which the stochastic diffusion factors are stored, the first `num_rates` components are the short-rates, the next `num_rates-1` are the associated cross-currency exchange rates against the reference currency (which is assumed to be the first, *ie* with id 0), and the last `num_spreads` are the stochastic intensity processes where the first one is for the bank and the rest are for the counterparties.\n",
    "\n",
    "As for the diffusion parameters, they can be set using the following correspondence with the notation in Appendix B of the article:\n",
    "* `rates_params['a'][e]` $\\leftrightarrow a^{\\langle e\\rangle}$;\n",
    "* `rates_params['b'][e]` $\\leftrightarrow b^{\\langle e\\rangle}$;\n",
    "* `rates_params['sigma'][e]` $\\leftrightarrow \\sigma^{r, \\langle e\\rangle}$;\n",
    "* `fx_params['vol'][e]` $\\leftrightarrow \\sigma^{\\chi, \\langle e\\rangle}$;\n",
    "* `spreads_params['a'][c]` $\\leftrightarrow \\alpha^{\\langle c\\rangle}$;\n",
    "* `spreads_params['b'][c]` $\\leftrightarrow \\delta^{\\langle c\\rangle}$;\n",
    "* `spreads_params['vvol'][c]` $\\leftrightarrow \\nu^{\\langle c\\rangle}$;\n",
    "\n",
    "Finally, for the products, one can set them in their `specs` arrays below. We invite the user to see the pricing functions in `compile_cuda_diffuse_and_price` (simulation/kernels.py) for more details on how they are used.\n",
    "\n",
    "In the following, we fill the diffusion parameters and the product specs randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coarse_steps = 100\n",
    "dT = 0.1\n",
    "num_fine_per_coarse = 25\n",
    "dt = 0.004\n",
    "num_paths = 2**15\n",
    "num_inner_paths = 1024\n",
    "num_defs_per_path = 256\n",
    "num_rates = 10\n",
    "num_spreads = 9\n",
    "R = np.eye(2*num_rates-1+num_spreads, dtype=np.float32) # we set the correlation matrix to the identity matrix, although not needed\n",
    "initial_values = np.empty(2*num_rates-1+num_spreads, dtype=np.float32)\n",
    "initial_defaults = np.empty((num_spreads-1+7)//8, dtype=np.int8)\n",
    "\n",
    "# rates diffusion parameters\n",
    "rates_params = np.empty(num_rates, dtype=[('a', '<f4'), ('b', '<f4'), ('sigma', '<f4')])\n",
    "rates_params['a'] = np.random.normal(0.4, 0.03, num_rates)\n",
    "rates_params['b'] = np.random.normal(0.03, 0.001, num_rates)\n",
    "rates_params['sigma'] = np.abs(np.random.normal(0.0025, 0.00025, num_rates))\n",
    "initial_values[:num_rates] = 0.01\n",
    "\n",
    "# FX diffusion parameters\n",
    "fx_params = np.empty(num_rates-1, dtype=[('vol', '<f4')])\n",
    "fx_params['vol'] = np.abs(np.random.normal(0.25, 0.025, num_rates-1))\n",
    "initial_values[num_rates:2*num_rates-1] = 1\n",
    "\n",
    "# stochastic intensities diffusion parameters\n",
    "spreads_params = np.empty(num_spreads, dtype=[('a', '<f4'), ('b', '<f4'), ('vvol', '<f4')])\n",
    "spreads_params['a'] = np.random.normal(0.5, 0.03, num_spreads)\n",
    "spreads_params['b'] = np.random.normal(0.01, 0.001, num_spreads)\n",
    "spreads_params['vvol'] = np.abs(np.random.normal(0.0075, 0.00075, num_spreads))\n",
    "initial_values[2*num_rates-1:] = 0.01\n",
    "\n",
    "# initial default indicators\n",
    "initial_defaults[:] = 0\n",
    "\n",
    "# length of simulated path on the GPU (paths are then simulated by chunks of cDtoH_freq until maturity)\n",
    "cDtoH_freq = 20\n",
    "\n",
    "# product specs (DO NOT use the ZCs)\n",
    "num_vanillas = 0\n",
    "vanilla_specs = np.empty(num_vanillas,\n",
    "                         dtype=[('maturity', '<f4'), ('notional', '<f4'),\n",
    "                                ('strike', '<f4'), ('cpty', '<i4'),\n",
    "                                ('undl', '<i4'), ('call_put', '<b1')])\n",
    "\n",
    "num_irs = 500\n",
    "irs_specs = np.empty(num_irs,\n",
    "                     dtype=[('first_reset', '<f4'), ('reset_freq', '<f4'),\n",
    "                            ('notional', '<f4'), ('swap_rate', '<f4'),\n",
    "                            ('num_resets', '<i4'), ('cpty', '<i4'),\n",
    "                            ('undl', '<i4')])\n",
    "\n",
    "irs_specs['first_reset'] = 0.  # First reset date in the swaps\n",
    "irs_specs['reset_freq'] = 0.2  # Reset frequency\n",
    "irs_specs['notional'] = 10000. * \\\n",
    "    ((np.random.choice((-1, 1), num_irs, p=(0.5, 0.5)))\n",
    "     * np.random.choice(range(1, 11), num_irs))  # Notional of the swaps\n",
    "irs_specs['swap_rate'] = np.abs(np.random.normal(0.03, 0.001, num_irs))  # Swap rate, not needed, swaps are priced at par anyway\n",
    "irs_specs['num_resets'] = np.random.randint(6, 51, num_irs, np.int32)  # Number of resets (num_resets*reset_freq should be equal to the desired maturity)\n",
    "irs_specs['cpty'] = np.random.randint(0, num_spreads-1, num_irs, np.int32)  # Counterparty with which the swap was entered into\n",
    "irs_specs['undl'] = np.random.randint(0, num_rates-1, num_irs, np.int32)  # Underlying currency\n",
    "\n",
    "num_zcs = 0\n",
    "zcs_specs = np.empty(num_zcs,\n",
    "                     dtype=[('maturity', '<f4'), ('notional', '<f4'),\n",
    "                            ('cpty', '<i4'), ('undl', '<i4')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the GPU. Should be `cuda:0` if there is only one GPU available. This is where both the simulation and the training/inference are going to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then instantiate the diffusion engine and the estimators (one with default indicators and the other with default intensities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully compiled all kernels.\n"
     ]
    }
   ],
   "source": [
    "diffusion_engine = DiffusionEngine(50, 50, num_coarse_steps, dT, num_fine_per_coarse, dt,\n",
    "                                   num_paths, num_inner_paths, num_defs_per_path, \n",
    "                                   num_rates, num_spreads, R, rates_params, fx_params, \n",
    "                                   spreads_params, vanilla_specs, irs_specs, zcs_specs,\n",
    "                                   initial_values, initial_defaults, cDtoH_freq, device.index)\n",
    "\n",
    "# selector for previous swap resets, need the states at those dates because of how the small non-Markovianity in the swap prices\n",
    "prev_reset_arr = (np.arange(num_coarse_steps+1)-1)//2*2\n",
    "\n",
    "# learner with default indicators\n",
    "cva_estimator_portfolio_def = CVAEstimatorPortfolioDef(prev_reset_arr, True, False, False, diffusion_engine, \n",
    "                                                       device, 1, 2*(num_rates+num_spreads), (num_defs_per_path*num_paths)//32, \n",
    "                                                       8, 0.01, 0, reset_weights=False, linear=False, best_sol=True)\n",
    "\n",
    "# learner with default intensities\n",
    "cva_estimator_portfolio_int = CVAEstimatorPortfolioInt(prev_reset_arr, True, False, False, diffusion_engine, \n",
    "                                                       device, 1, 2*(num_rates+num_spreads), (num_defs_per_path*num_paths)//32, \n",
    "                                                       8, 0.01, 0, reset_weights=False, linear=False, best_sol=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We launch a first set of simulations in order to have paths on which to train on. This will simulate the risk factors and do all the pricings at the coarse time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_diffuse_and_price elapsed time: 896.563 ms\n"
     ]
    }
   ],
   "source": [
    "diffusion_engine.generate_batch(fused=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a generator for the feature and tell it to keep the data in CUDA memory and implicitly copy when assigning to Numpy arrays, and then we launch the training for the default indicators version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using default indicators...done in 613.96 secs\n"
     ]
    }
   ],
   "source": [
    "features_gen = cva_estimator_portfolio_def._build_features()\n",
    "print('Training using default indicators...', end='')\n",
    "_chrono_start = time.time()\n",
    "cva_estimator_portfolio_def.train(features_gen=features_gen, labels_as_cuda_tensors=True)\n",
    "_chrono_end = time.time()\n",
    "elapsed_time_def = _chrono_end - _chrono_start\n",
    "print('done in {} secs'.format(round(elapsed_time_def, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, a Neural Network estimator has been trained and the weights for any time-step `i` have been stored in the `.saved_states[i]`, *ie* if one wants to look at the parameters at time-step 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " (OrderedDict([('h.0.W',\n",
       "                tensor([[ 0.0333,  0.2564,  0.0654,  ...,  0.1069, -0.0160,  0.0232],\n",
       "                        [-0.3023,  0.4546, -0.0329,  ..., -0.0536, -0.1726, -0.1027],\n",
       "                        [-0.0704,  0.0287,  0.4041,  ..., -0.2411,  0.2727,  0.3581],\n",
       "                        ...,\n",
       "                        [-0.0482,  0.0085,  0.0669,  ..., -0.3238, -0.1045, -0.2775],\n",
       "                        [ 0.0684, -0.0813,  0.0170,  ...,  0.0893, -0.0234,  0.0745],\n",
       "                        [-0.3766, -0.0283, -0.0242,  ..., -0.1842, -0.9649, -0.2864]],\n",
       "                       device='cuda:2')),\n",
       "               ('h.0.b',\n",
       "                tensor([[-5.8207, -5.3954, -5.4814, -3.0244, -4.9950, -5.9605, -6.1695, -4.9049,\n",
       "                         -3.7649, -1.4537, -4.0437, -6.3660, -5.4695, -4.6541, -6.1696, -5.2418,\n",
       "                         -4.6693, -4.7459, -3.7195, -3.4973,  0.6176, -5.7684, -5.9582, -5.1127,\n",
       "                         -3.3992, -4.6477, -7.2551, -4.3348, -5.6854, -4.0213, -5.7223, -5.1061,\n",
       "                         -4.9542, -1.7461, -3.5814, -4.7218, -7.9625, -5.0621]],\n",
       "                       device='cuda:2')),\n",
       "               ('o.W',\n",
       "                tensor([[ 0.3759],\n",
       "                        [-0.2166],\n",
       "                        [-0.2580],\n",
       "                        [ 0.0917],\n",
       "                        [-0.0997],\n",
       "                        [ 0.4611],\n",
       "                        [-0.3949],\n",
       "                        [-0.1195],\n",
       "                        [-0.1499],\n",
       "                        [-0.0273],\n",
       "                        [-0.0990],\n",
       "                        [-0.3329],\n",
       "                        [ 0.3843],\n",
       "                        [ 0.3515],\n",
       "                        [-0.3229],\n",
       "                        [ 0.3268],\n",
       "                        [-0.1137],\n",
       "                        [-0.1788],\n",
       "                        [-0.1077],\n",
       "                        [-0.0904],\n",
       "                        [ 0.0319],\n",
       "                        [-0.1971],\n",
       "                        [ 0.8541],\n",
       "                        [ 0.3596],\n",
       "                        [ 0.1424],\n",
       "                        [ 0.1822],\n",
       "                        [ 0.6135],\n",
       "                        [-0.1510],\n",
       "                        [ 0.3306],\n",
       "                        [-0.1471],\n",
       "                        [-0.1119],\n",
       "                        [-0.2007],\n",
       "                        [-0.2145],\n",
       "                        [-0.0559],\n",
       "                        [ 0.1181],\n",
       "                        [-0.1021],\n",
       "                        [ 0.9779],\n",
       "                        [ 0.2592]], device='cuda:2')),\n",
       "               ('o.b', tensor([[0.2638]], device='cuda:2')),\n",
       "               ('o.a', tensor(True, device='cuda:2')),\n",
       "               ('o.c', tensor(0.0108, device='cuda:2'))]),\n",
       "  {'state': {0: {'step': 13216,\n",
       "     'exp_avg': tensor([[ 1.5974e-05, -2.8829e-06, -8.0884e-06,  ..., -8.0076e-06,\n",
       "               4.7934e-06,  1.6932e-05],\n",
       "             [-4.8191e-06, -1.8439e-05,  1.2279e-05,  ..., -5.3115e-06,\n",
       "              -2.1601e-06,  8.4869e-06],\n",
       "             [-6.8740e-06,  1.5985e-05,  5.1372e-06,  ...,  1.3482e-05,\n",
       "              -2.3007e-05, -1.3779e-05],\n",
       "             ...,\n",
       "             [-1.3983e-05,  4.5559e-06, -1.1123e-05,  ...,  8.9028e-07,\n",
       "              -1.0338e-06, -1.0214e-06],\n",
       "             [-1.9234e-05, -1.6994e-06,  2.6545e-05,  ..., -2.4175e-06,\n",
       "              -9.8190e-06, -5.9249e-06],\n",
       "             [-7.0525e-07, -2.8424e-07, -2.2093e-06,  ...,  1.8045e-07,\n",
       "               6.1778e-06,  1.3829e-06]], device='cuda:2'),\n",
       "     'exp_avg_sq': tensor([[6.7415e-09, 3.0805e-09, 1.6198e-09,  ..., 1.2854e-09, 9.6003e-09,\n",
       "              7.1434e-09],\n",
       "             [1.3529e-08, 5.3912e-09, 2.0654e-09,  ..., 1.6801e-09, 1.9219e-08,\n",
       "              6.5080e-09],\n",
       "             [7.5680e-09, 2.9391e-09, 1.8613e-09,  ..., 1.2933e-09, 1.0232e-08,\n",
       "              9.8372e-09],\n",
       "             ...,\n",
       "             [1.0169e-08, 4.1721e-09, 1.4321e-09,  ..., 8.8695e-10, 2.9561e-09,\n",
       "              1.1592e-09],\n",
       "             [3.0031e-08, 2.1115e-09, 1.7228e-09,  ..., 2.2151e-09, 2.6742e-08,\n",
       "              9.1830e-09],\n",
       "             [3.5640e-10, 1.2641e-10, 1.3262e-10,  ..., 6.5365e-11, 1.1274e-09,\n",
       "              2.1478e-10]], device='cuda:2')},\n",
       "    1: {'step': 13216,\n",
       "     'exp_avg': tensor([[ 5.9634e-06,  1.0504e-06,  1.4837e-05, -5.8294e-06, -6.6267e-06,\n",
       "               1.5747e-05,  9.1891e-06,  1.0716e-05, -4.3377e-06, -5.8880e-06,\n",
       "              -1.7449e-05,  1.7632e-05,  3.7793e-05, -5.0174e-06, -2.1497e-05,\n",
       "               1.1827e-05, -5.0874e-06,  8.0098e-06,  1.7435e-06, -6.7882e-06,\n",
       "              -1.3607e-05,  2.5433e-05, -2.8427e-05, -4.0772e-05,  2.5176e-06,\n",
       "              -1.2098e-05,  1.0487e-05,  3.4910e-06, -1.1044e-05,  1.2796e-05,\n",
       "               6.7981e-06,  7.5129e-06, -7.8051e-06,  1.2598e-05,  2.9864e-05,\n",
       "              -1.5702e-06, -4.0811e-05, -9.0454e-06]], device='cuda:2'),\n",
       "     'exp_avg_sq': tensor([[8.3398e-09, 3.2335e-09, 2.2020e-09, 1.6958e-08, 3.2205e-09, 1.4424e-08,\n",
       "              4.2052e-09, 4.5835e-09, 2.1773e-09, 3.4124e-09, 3.6126e-09, 3.1463e-09,\n",
       "              1.4856e-08, 1.4175e-08, 4.4090e-09, 7.7878e-09, 1.1297e-09, 4.4552e-09,\n",
       "              3.3547e-09, 3.3588e-09, 1.0753e-07, 4.3009e-09, 1.9205e-08, 1.2933e-08,\n",
       "              6.8643e-09, 8.1577e-09, 1.7257e-08, 3.6994e-09, 1.3341e-08, 8.2698e-10,\n",
       "              1.7870e-09, 4.7854e-09, 3.3571e-09, 3.0242e-09, 7.3017e-09, 1.5021e-09,\n",
       "              1.6534e-08, 6.4503e-09]], device='cuda:2')},\n",
       "    2: {'step': 13216,\n",
       "     'exp_avg': tensor([[ 6.9106e-05],\n",
       "             [ 6.0545e-05],\n",
       "             [-2.9286e-05],\n",
       "             [-1.1303e-04],\n",
       "             [ 8.8544e-05],\n",
       "             [ 9.7524e-05],\n",
       "             [ 3.7558e-05],\n",
       "             [-4.4398e-05],\n",
       "             [-4.9260e-05],\n",
       "             [ 1.0910e-03],\n",
       "             [ 1.0915e-04],\n",
       "             [-1.9213e-05],\n",
       "             [ 1.0496e-04],\n",
       "             [ 4.9069e-05],\n",
       "             [ 1.0460e-04],\n",
       "             [ 8.0854e-05],\n",
       "             [ 9.3150e-05],\n",
       "             [ 5.0157e-05],\n",
       "             [ 1.3448e-04],\n",
       "             [ 1.0738e-04],\n",
       "             [-1.9431e-04],\n",
       "             [-1.3183e-04],\n",
       "             [-2.9655e-05],\n",
       "             [-7.6555e-05],\n",
       "             [ 1.2705e-04],\n",
       "             [-1.2612e-04],\n",
       "             [-1.0039e-06],\n",
       "             [-7.2458e-06],\n",
       "             [-5.8451e-05],\n",
       "             [-1.5147e-05],\n",
       "             [-1.5733e-05],\n",
       "             [ 4.5436e-06],\n",
       "             [ 7.6778e-05],\n",
       "             [-3.0181e-05],\n",
       "             [ 8.5137e-05],\n",
       "             [ 1.8438e-05],\n",
       "             [-6.5110e-05],\n",
       "             [-6.9574e-05]], device='cuda:2'),\n",
       "     'exp_avg_sq': tensor([[3.4493e-07],\n",
       "             [4.2663e-07],\n",
       "             [2.9961e-07],\n",
       "             [4.3520e-06],\n",
       "             [3.0675e-07],\n",
       "             [4.2878e-07],\n",
       "             [3.9893e-07],\n",
       "             [3.6682e-07],\n",
       "             [2.5474e-07],\n",
       "             [1.1469e-05],\n",
       "             [6.8507e-07],\n",
       "             [4.0079e-07],\n",
       "             [3.3067e-07],\n",
       "             [3.6295e-07],\n",
       "             [3.6276e-07],\n",
       "             [3.2749e-07],\n",
       "             [3.0059e-07],\n",
       "             [2.7879e-07],\n",
       "             [4.2873e-07],\n",
       "             [1.2762e-06],\n",
       "             [6.9276e-04],\n",
       "             [4.0968e-07],\n",
       "             [3.9179e-07],\n",
       "             [2.8189e-07],\n",
       "             [1.0092e-06],\n",
       "             [7.4969e-07],\n",
       "             [5.8438e-07],\n",
       "             [2.9289e-07],\n",
       "             [6.3884e-07],\n",
       "             [2.2954e-07],\n",
       "             [4.1164e-07],\n",
       "             [3.8344e-07],\n",
       "             [2.7254e-07],\n",
       "             [4.9438e-06],\n",
       "             [1.0860e-06],\n",
       "             [3.0158e-07],\n",
       "             [6.3355e-07],\n",
       "             [3.9862e-07]], device='cuda:2')},\n",
       "    3: {'step': 13216,\n",
       "     'exp_avg': tensor([[-0.0005]], device='cuda:2'),\n",
       "     'exp_avg_sq': tensor([[0.0001]], device='cuda:2')}},\n",
       "   'param_groups': [{'lr': 0.01,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'params': [0, 1, 2, 3]}]},\n",
       "  array([0.02201093, 0.02205416, 0.02196624, 0.0222256 , 0.02225352,\n",
       "         0.02064592, 0.02237421, 0.02085662, 0.0211246 , 0.02075678,\n",
       "         1.0016671 , 0.99932104, 1.0037513 , 0.9995551 , 1.0087243 ,\n",
       "         1.0002671 , 1.0025522 , 1.0049113 , 1.0016688 , 0.00987607,\n",
       "         0.00946737, 0.01022379, 0.00965474, 0.00926353, 0.00998345,\n",
       "         0.01025862, 0.01004181, 0.02123803, 0.02123856, 0.02118208,\n",
       "         0.02144331, 0.02146144, 0.01990489, 0.02155852, 0.02011073,\n",
       "         0.02035668, 0.02003596, 0.01969647, 0.03837705, 0.08014965,\n",
       "         0.15580177, 0.30259705, 0.6342926 , 1.2828827 , 2.5423431 ],\n",
       "        dtype=float32),\n",
       "  array([1.7893837e-03, 2.6382376e-03, 2.6581378e-03, 2.2052163e-03,\n",
       "         2.9277701e-03, 2.1843410e-03, 2.4435534e-03, 2.4713143e-03,\n",
       "         2.8953003e-03, 2.8316258e-03, 3.6995876e-01, 3.8191521e-01,\n",
       "         3.2994205e-01, 2.8989679e-01, 3.5514060e-01, 3.7245607e-01,\n",
       "         4.1159588e-01, 4.1280884e-01, 3.4736371e-01, 6.6895073e-04,\n",
       "         6.7677774e-04, 6.8117579e-04, 6.3924212e-04, 6.3441187e-04,\n",
       "         5.8315240e-04, 7.3382375e-04, 6.5956026e-04, 1.7599402e-03,\n",
       "         2.5802620e-03, 2.6008710e-03, 2.1753982e-03, 2.8703264e-03,\n",
       "         2.1315010e-03, 2.3948229e-03, 2.4113422e-03, 2.8434473e-03,\n",
       "         2.7700532e-03, 1.3895510e-01, 2.7437422e-01, 5.6051308e-01,\n",
       "         1.1055052e+00, 2.1794469e+00, 4.4603868e+00, 8.9698858e+00,\n",
       "         1.7859341e+01], dtype=float32),\n",
       "  array([634.08844], dtype=float32)))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cva_estimator_portfolio_def.saved_states[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the first component is `True`. When it instead is `False`, it simply means that no learning has been done, because either it was the first time-step (simple unconditional average) or a time-step at which the labels have numerically zero variance (in which case the conditional expectation is simply the unconditional average)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are replacing the old features generator, implicitly freeing up memory and letting PyTorch and CUDA reuse buffers, and then we launch as previously the training for the default intensities version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using default intensities...done in 611.45 secs\n"
     ]
    }
   ],
   "source": [
    "features_gen = cva_estimator_portfolio_int._build_features()\n",
    "print('Training using default intensities...', end='')\n",
    "_chrono_start = time.time()\n",
    "cva_estimator_portfolio_int.train(features_gen=features_gen, labels_as_cuda_tensors=True)\n",
    "_chrono_end = time.time()\n",
    "elapsed_time_def = _chrono_end - _chrono_start\n",
    "print('done in {} secs'.format(round(elapsed_time_def, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to output CVA values from our trained learners. We first launch a new set of paths. This time, we tell the diffusion engine to run a Nested Monte Carlo simulation at time-steps 25 and 50 in order to get a NMC estimator of the CVA at those time-steps, which will be used as a benchmark against which we will compare the learners below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_diffuse_and_price elapsed time: 857.643 ms\n",
      "cuda_nested_cva average elapsed time per launch: 460308.829 ms\n"
     ]
    }
   ],
   "source": [
    "nested_timesteps = [25, 50]\n",
    "diffusion_engine.generate_batch(fused=True, nested_cva_at=nested_timesteps, indicator_in_cva=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform inference, one needs to create a *predictor* (via `.predict`) and then iterate over the time-steps and call it as below to generate the predictions. Note that the predictor will also need a features generator, which we need to recreate here (would have been unnecessary if we had only one learner instead of two, which would have allowed us to keep the features generator used during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference (NN with default indicators)..."
     ]
    }
   ],
   "source": [
    "print('Performing inference (NN with default indicators)...', end='')\n",
    "_chrono_start = time.time()\n",
    "features_gen = cva_estimator_portfolio_def._build_features()\n",
    "predictor = cva_estimator_portfolio_def.predict(features_gen=features_gen, as_cuda_array=True, flatten=False)\n",
    "predicted_cva_portfolio_def_out = np.empty((num_coarse_steps+1, num_defs_per_path*num_paths), dtype=np.float32)\n",
    "_v = predicted_cva_portfolio_def_out.reshape(num_coarse_steps+1, num_defs_per_path, num_paths)\n",
    "for t in range(num_coarse_steps, -1, -1):\n",
    "    next(predictor)\n",
    "    _v[t] = predictor.send(t)\n",
    "_chrono_end = time.time()\n",
    "elapsed_time_def = _chrono_end - _chrono_start\n",
    "print('done in {} secs'.format(round(elapsed_time_def, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the default intensities version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing inference (NN with default intensities)...', end='')\n",
    "_chrono_start = time.time()\n",
    "features_gen = cva_estimator_portfolio_int._build_features()\n",
    "predictor = cva_estimator_portfolio_int.predict(features_gen=features_gen, as_cuda_array=True, flatten=False)\n",
    "predicted_cva_portfolio_int_out = np.empty((num_coarse_steps+1, num_defs_per_path*num_paths), dtype=np.float32)\n",
    "_v = predicted_cva_portfolio_int_out.reshape(num_coarse_steps+1, num_defs_per_path, num_paths)\n",
    "for t in range(num_coarse_steps, -1, -1):\n",
    "    next(predictor)\n",
    "    _v[t] = predictor.send(t)\n",
    "_chrono_end = time.time()\n",
    "elapsed_time_def = _chrono_end - _chrono_start\n",
    "print('done in {} secs'.format(round(elapsed_time_def, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot a few statistics of the learned CVAs along the time axis (unconditional mean & a few percentiles) and also plot the same statistics for our NMC estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(12, 3), dpi=100)\n",
    "axes[0].plot(predicted_cva_portfolio_def_out.mean(axis=1), label='Mean of learned CVA, out-of-sample', color='purple')\n",
    "axes[0].plot(np.percentile(predicted_cva_portfolio_def_out, 99, axis=1), label=r'99\\% percentile of learned CVA, out-of-sample', color='blue', linestyle='dashdot')\n",
    "axes[0].plot(np.percentile(predicted_cva_portfolio_def_out, 1, axis=1), label=r'1\\% percentile of learned CVA, out-of-sample', color='tab:cyan', linestyle=(0, (3, 10, 1, 10)))\n",
    "axes[0].plot(np.percentile(predicted_cva_portfolio_def_out, 97.5, axis=1), label=r'97.5\\% percentile of learned CVA, out-of-sample', color='burlywood', linestyle='dashed')\n",
    "axes[0].plot(np.percentile(predicted_cva_portfolio_def_out, 2.5, axis=1), label=r'2.5\\% percentile of learned CVA, out-of-sample', color='saddlebrown', linestyle='dotted')\n",
    "axes[0].plot(nested_timesteps, diffusion_engine.nested_cva[nested_timesteps, 0].mean(axis=1), marker='s', linestyle='None', label='Mean of Nested Monte-Carlo CVA, out-of-sample', color='black')\n",
    "axes[0].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 97.5, axis=1), marker='^', linestyle='None', label=r'97.5\\% percentile of Nested Monte-Carlo CVA, out-of-sample', color='orange')\n",
    "axes[0].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 2.5, axis=1), marker='v', linestyle='None', label=r'2.5\\% percentile of Nested Monte-Carlo CVA, out-of-sample', color='gray')\n",
    "axes[0].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 99, axis=1), marker='x', linestyle='None', label=r'99\\% percentile of Nested Monte-Carlo CVA, out-of-sample', color='red')\n",
    "axes[0].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 1, axis=1), marker='+', linestyle='None', label=r'1\\% percentile of Nested Monte-Carlo CVA, out-of-sample', color='green')\n",
    "axes[0].text(.5, .9,'using default indicators'.format(1), horizontalalignment='center', transform=axes[0].transAxes)\n",
    "axes[1].plot(predicted_cva_portfolio_int_out.mean(axis=1), label='Mean of learned CVA, out-of-sample', color='purple')\n",
    "axes[1].plot(np.percentile(predicted_cva_portfolio_int_out, 99, axis=1), label=r'99\\% percentile of learned CVA, out-of-sample', color='blue', linestyle='dashdot')\n",
    "axes[1].plot(np.percentile(predicted_cva_portfolio_int_out, 1, axis=1), label=r'1\\% percentile of learned CVA, out-of-sample', color='tab:cyan', linestyle=(0, (3, 10, 1, 10)))\n",
    "axes[1].plot(np.percentile(predicted_cva_portfolio_int_out, 97.5, axis=1), label=r'97.5\\% percentile of learned CVA, out-of-sample', color='burlywood', linestyle='dashed')\n",
    "axes[1].plot(np.percentile(predicted_cva_portfolio_int_out, 2.5, axis=1), label=r'2.5\\% percentile of learned CVA, out-of-sample', color='saddlebrown', linestyle='dotted')\n",
    "axes[1].plot(nested_timesteps, diffusion_engine.nested_cva[nested_timesteps, 0].mean(axis=1), marker='s', linestyle='None', label='Mean of Nested MC CVA, out-of-sample', color='black')\n",
    "axes[1].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 97.5, axis=1), marker='^', linestyle='None', label=r'97.5\\% percentile of Nested MC CVA, out-of-sample', color='orange')\n",
    "axes[1].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 2.5, axis=1), marker='v', linestyle='None', label=r'2.5\\% percentile of Nested MC CVA, out-of-sample', color='gray')\n",
    "axes[1].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 99, axis=1), marker='x', linestyle='None', label=r'99\\% percentile of Nested MC CVA, out-of-sample', color='red')\n",
    "axes[1].plot(nested_timesteps, np.percentile(diffusion_engine.nested_cva[nested_timesteps, 0], 1, axis=1), marker='+', linestyle='None', label=r'1\\% percentile of Nested MC CVA, out-of-sample', color='green')\n",
    "axes[1].text(.5, .9,'using default intensities'.format(1), horizontalalignment='center', transform=axes[1].transAxes)\n",
    "\n",
    "fig.subplots_adjust(top=0.9, left=0.1, right=0.9, bottom=0.12)\n",
    "lgd = axes.flatten()[-1].legend(loc='upper center', bbox_to_anchor=(-0.125, -0.12), ncol=2, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
